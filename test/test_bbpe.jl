using BytePairEncoding: default_codemap, GPT2Tokenization, Merge
using TextEncodeBase: FlatTokenizer, CodeNormalizer, Sentence, getvalue
using Downloads

@testset "ByteLevel" begin
    weird_sentence_answer = ["Ã°Ä¿", "Äº", "Ä²", "Ä ", "Ã°Ä¿", "Ä¹", "Ä¨", "Ã°Ä¿", "Ä¹", "Ä¤", "Ã°Ä¿", "Ä¹", "Â´", "Ã°Ä¿", "Äº", "Â©", "Ã°Ä¿", "Ä»", "Â©", "Ä ", "Ã°Ä¿", "Ä¼", "Ä·", "Ã°Ä¿", "Ä¼", "Äº", "Ã°Ä¿", "Ä¼", "Äº", "k", "Ä ", "Ã°Ä¿", "Ä»", "Ä©", "Ã°Ä¿", "Äº", "Âª", "Ã°Ä¿", "Ä¹", "Â¸", "Ã°Ä¿", "Ä¸", "Â¾", "Ä ", "Ã°Ä¿", "Ä¸", "Ä¨", "Ä ", "Ã°Ä¿", "Ä¸", "Äµ", "Ã°Ä¿", "Ä¸", "Ä¶", "Ã°Ä¿", "Ä¸", "Ä¹", "Ã°Ä¿", "Ä·", "Å€", "Ã°Ä¿", "Ä·", "Ä´", "Ã°Ä¿", "Ä·", "Ä¿", "Ä ", "Ã°Ä¿", "Ä¶", "Â°", "Ã°Ä¿", "Äµ", "Â®", "Ã°Ä¿", "Äµ", "Ä¥", "Ã°Ä¿", "Ä´", "Ä·", "Ã°Ä¿", "Ä³", "Ä´", "Ã°Ä¿", "Ä²", "Â§", "ce"]

    bpe = BPE(Downloads.download("https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt"))
    tkr = FlatTokenizer(CodeNormalizer(BPETokenization(GPT2Tokenization(), bpe), default_codemap()))
    @test map(getvalue, tkr(Sentence("ð˜ ð—†ð—‚ð—´ð˜©ð™© ðš•ðš˜ðš˜k ð™‡ð˜ªð—¸ð–¾ ð–† ð–“ð–”ð–—ð•žð•’ð• ð”°ð“®ð“ƒð’•ð‘’ð§ce"))) == weird_sentence_answer

    merges = Dict(
        (Merge("\u0120")   , Merge("l")) => 1,
        (Merge("\u0120l")  , Merge("o")) => 2,
        (Merge("\u0120lo") , Merge("w")) => 3,
        (Merge("e")        , Merge("r")) => 4,
    )
    tkr1 = FlatTokenizer(CodeNormalizer(BPETokenization(GPT2Tokenization(), BPE(merges)), default_codemap()))
    @test map(getvalue, tkr1(Sentence(" lower newer"))) == ["\u0120low", "er", "\u0120", "n", "e", "w", "er"]
end
